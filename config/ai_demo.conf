[global]
listen_port = 18080
threads = 4
# 可选：roundrobin/hash/leastconn/leastqueue/rtw/gpu
strategy = gpu
log_level = INFO
io_model = epoll
reuse_port = 0

[health_check]
mode = http
http_host = 127.0.0.1
http_path = /health
interval = 1.0
timeout = 0.5

[ai_check]
enable = 1
http_host = 127.0.0.1
http_path = /ai/status
interval = 1.0
timeout = 0.5

[history]
enable = 1
sample_ms = 500
max_points = 3600
persist_path =

[audit_log]
path = ./logs/ai_demo_audit.log

[session_affinity]
# 为了演示“同一模型在多个后端间分配”，使用 header 做亲和 key，
# 并在压测请求里注入随机 X-Request-Id，使 selectionKey 变化，从而在候选后端中分散。
mode = header
header_name = X-Request-Id

[access_control]
ip_mode = off
require_token = 0
require_api_key = 0
